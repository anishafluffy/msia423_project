{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCode includes three functions: \\nclean_data - \\ncreate_model - \\npredict_response - \\nLogistic regression to classify cuisine from a string of ingredients\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Code includes three functions: \n",
    "clean_data - \n",
    "create_model - \n",
    "predict_response - \n",
    "Logistic regression to classify cuisine from a string of ingredients\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn import grid_search\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Function 1: import & clean data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(path):\n",
    "    #import data\n",
    "    df = pd.read_json(path)\n",
    "    #clean data\n",
    "    df['ingredients_clean_string'] = [' , '.join(z).strip() for z in df['ingredients']]  \n",
    "    df['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in df['ingredients']]       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data(\"../data/train.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 2: train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(training_df):\n",
    "    #instantiate vectorizer\n",
    "    vect = TfidfVectorizer(stop_words = 'english', #remove standard english stop words\n",
    "                           ngram_range = (1 , 1), #range of n-values for different n-grams to be extracted\n",
    "                           analyzer = \"word\", #feature made of word (not character) n-grams\n",
    "                           max_df = .57, #ignore terms that have a document frequency higher than threshold \n",
    "                           binary = False , \n",
    "                           token_pattern = r'\\w+' , #what constitutes a “token”\n",
    "                           sublinear_tf = False\n",
    "                          )\n",
    "    #use vectorizer on training corpus\n",
    "    predictors = vect.fit_transform(df['ingredients_string']).todense()\n",
    "    #define response\n",
    "    response = df['cuisine']\n",
    "    #instantiate model\n",
    "    clf = LogisticRegression()\n",
    "    #train the model\n",
    "    parameters = {'C':[1, 10]}\n",
    "    classifier = GridSearchCV(clf, parameters)\n",
    "    classifier = classifier.fit(predictors, response) \n",
    "    # return vect, classifier\n",
    "\n",
    "    #create pickle files\n",
    "    joblib.dump(vect, 've.pkl') \n",
    "    joblib.dump(classifier, 'cl.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vect, classifier = train_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 3: predict cuisine for user inputted list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_response(user_input):\n",
    "    #load pickle vectorizer & classifier\n",
    "    vect = joblib.load('ve.pkl')\n",
    "    classifier = joblib.load('cl.pkl')\n",
    "    \n",
    "    #vectorize the input\n",
    "    predictors_input = vect.transform([user_input])\n",
    "    predictors_input.toarray()\n",
    "    \n",
    "    #predict response\n",
    "    response_output = ''.join(classifier.predict(predictors_input))\n",
    "    return response_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chinese'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_response('kung pao chicken')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
